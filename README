/**********************************************
 * Please DO NOT MODIFY the format of this file
 **********************************************/

/*************************
 * Team Info & Time spent
 *************************/
/*
	Edit this to list all group members and time spent.
	Please follow the format or our scripts will break. 
*/

	Name1: Andrew Gauthier
	NetId1: ajg45 
	Time spent: 16 hours

	Name2: Jeff Day
	NetId2: rd22 
	Time spent: 16 hours

	Name3: Clive Mudanda
	NetId3: cmm85
	Time spent: 16 hours

/******************
 * Files to submit
 ******************/

	dsh.c 	// Header file is not necessary; other *.c files if necessary
	README	// This file filled with the lab implementation details

/************************
 * Implementation details
 *************************/

/* 
 * This section should contain the implementation details and a overview of the
 * results. 

 * You are expected to provide a good README document including the
 * implementation details. In particular, you can use pseudocode to describe your
 * implementation details where necessary. However that does not mean to
 * copy/paste your C code. Specifically, you should summarize details corresponding 
 * to (1) multiple pipelines (2) job control (3) logging (3) .c commands 
 * compilation and execution. We expect the design and implementation details to 
 * be at most 1-2 pages.  A plain textfile is requested. 

 * In case of lab is limited in some functionality, you should provide the
 * details to maximize your partial credit.  
 * */

For implementation of commands from the command line of our shell we first checked whether 
the job was already built in in the builtin_cmd() method. If the job isnâ€™t built in then the 
main sends it to the spawn_job() with a boolean that marks whether it runs in the background 
or in the foreground.

For specific built in commands,  the method returns true if the passed in command is found 
and false otherwise. Also, when a command if found in the built in method, we mark is as completed 
assuming it has already been executed.The way we looks for the jobs is just by looping through the 
job_t structure and add it to our running processes.

When we spawn the jobs, we first create a pipe before we fork into our child processes inorder to 
be able to run multiple processes. For the child process, we first take care of redirection i.e. 
redirecting the input and output files then pipe the process before actually perfoming an execvp. 
The pipe is then closed after the parent process had returned since we wont need to use it any more.

(2) job control
For foreground jobs we checked for the status of the signals, Cntrl + Z send a WIFSTOPPED signal hence when the 
user presses this we set the job to stopped. After doing this we seized the terminal back from the shell so that 
we could exit out of the running proccess without actually exiting our shell.

(1) multiple pipelines
For multiple pipelines we create two pipes which alternate processes i.e. pipe1 does the first process 
and pipe2 does the next process. By the time we have gotten to the third process, the first pipe would 
have been closed hence can be used for this processing.
We use dup2() to duplicate the file descriptor of our pipe so that we can be able to close it afterwards,
eg:
	dup2(pfd[0], fileno(stdin));

(3) logging

We put print statements to check for errors especially utilizing the perror() method which allow us to 
debug child process since printf() doesnt have access to the terminal in these processes.


/************************
 * Feedback on the lab
 ************************/

/*
 * Any comments/questions/suggestions/experiences that you would help us to
 * improve the lab.
 * */


/************************
 * References
 ************************/

/*
 * List of collaborators involved including any online references/citations.
 * */

http://linux.die.net/man/
http://www.cs.duke.edu/~chase/cps310/internal/controlflow.pdf
http://pages.cs.wisc.edu/~remzi/OSTEP/cpu-api.pdf
http://www.cs.duke.edu/~chase/cps310/projects/lab2/lab2-faq.txt
